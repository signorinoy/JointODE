---
title: "Technical Details"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Technical Details}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

This vignette describes the mathematical framework and computational implementation of the JointODE model, which jointly models longitudinal biomarker trajectories and survival outcomes through a coupled ordinary differential equation (ODE) system.

## Model Framework

### State Variables

The model tracks three state variables for each subject $i$:

- $\Lambda_i(t)$: Cumulative hazard
- $m_i(t)$: Biomarker level
- $\dot{m}_i(t)$: Biomarker velocity (rate of change)

### ODE System

The state vector $\mathbf{s}_i(t) = (\Lambda_i(t), m_i(t), \dot{m}_i(t))^{\top}$ evolves according to:

$$
\frac{d\mathbf{s}_i}{dt} = \begin{pmatrix}
\lambda_i(t|b_i) \\
\dot{m}_i(t) \\
g(\boldsymbol{\beta}^{\top}\mathbf{Z}_i(t))
\end{pmatrix}
$$

with initial conditions $\mathbf{s}_i(0) = (0, m_{i0}, \dot{m}_{i0})^{\top}$.

### Model Components

**Hazard Function:**
$$\lambda_i(t|b_i) = \exp\left[\boldsymbol{\eta}^{\top} \mathbf{B}^{(\lambda)}(t) + \boldsymbol{\alpha}^{\top}\mathbf{m}_i(t) + b_{i} + \mathbf{W}_i^{\top}\boldsymbol{\phi}\right]$$

- $\mathbf{B}^{(\lambda)}(t)$: B-spline basis for baseline hazard
- $\mathbf{m}_i(t) = (m_i(t), \dot{m}_i(t), \ddot{m}_i(t))^{\top}$: Biomarker features
- $b_i$: Subject-specific random effect
- $\mathbf{W}_i$: Baseline covariates

**Acceleration Function:**
$$g(u) = \boldsymbol{\theta}^{\top} \mathbf{B}^{(g)}(u), \quad u = \boldsymbol{\beta}^{\top}\mathbf{Z}_i(t)$$

- $\mathbf{B}^{(g)}(u)$: B-spline basis for acceleration
- $\mathbf{Z}_i(t) = (m_i(t), \dot{m}_i(t), \mathbf{X}_i(t)^{\top}, t)^{\top}$: Feature vector
- $\boldsymbol{\beta}$: Single-index coefficients (constrained: $\|\boldsymbol{\beta}\| = 1$)

## Statistical Inference

### Likelihood

The joint likelihood for subject $i$ integrates over the random effect:

$$L_i(\boldsymbol{\Theta}) = \int f(\mathbf{V}_i | b_i) \cdot f(T_i, \delta_i | b_i) \cdot f(b_i) \, db_i$$

where $\boldsymbol{\Theta} = (\boldsymbol{\theta}, \boldsymbol{\beta}, \boldsymbol{\eta}, \boldsymbol{\alpha}, \boldsymbol{\phi}, \sigma_e^2, \sigma_b^2)$.

**Likelihood Components:**

1. **Longitudinal:** $f(\mathbf{V}_i | b_i) = \prod_{j=1}^{n_i} \mathcal{N}(V_{ij}; m_i(T_{ij}) + b_i, \sigma_e^2)$
2. **Survival:** $f(T_i, \delta_i | b_i) = [\lambda_i(T_i|b_i)]^{\delta_i} \exp[-\Lambda_i(T_i|b_i)]$
3. **Random Effect:** $f(b_i) \sim \mathcal{N}(0, \sigma_b^2)$

### EM Algorithm

We use an Expectation-Maximization (EM) algorithm for parameter estimation.

#### E-Step: Posterior Computation

For each subject $i$, compute the posterior distribution of $b_i$ given observed data $\mathcal{O}_i$.

**Key simplification:** The hazard and cumulative hazard factor as:

- $\lambda_i(t|b_i) = e^{b_i} \lambda_i(t|0)$
- $\Lambda_i(t|b_i) = e^{b_i} \Lambda_i(t|0)$

**Implementation:**

1. **Solve baseline ODE** with $b_i = 0$ to obtain $m_i(t)$, $\lambda_i(t|0)$, $\Lambda_i(T_i|0)$
2. **Find posterior mode** $\tilde{b}_i$ by maximizing:
   $$\ell_i(b) = b\left[\frac{S_i}{\sigma_e^2} + \delta_i\right] - \frac{b^2}{2}\left[\frac{n_i}{\sigma_e^2} + \frac{1}{\sigma_b^2}\right] - e^b\Lambda_i(T_i|0)$$
   where $S_i = \sum_j(V_{ij} - m_i(T_{ij}))$
3. **Compute posterior moments** via adaptive Gauss-Hermite quadrature:
   - Mean: $\hat{b}_i = E[b_i|\mathcal{O}_i]$
   - Variance: $\hat{v}_i = \text{Var}[b_i|\mathcal{O}_i]$
   - Transform: $E[e^{b_i}|\mathcal{O}_i]$ for survival updates

#### M-Step: Parameter Updates

Maximize the expected complete-data log-likelihood:

$$Q(\boldsymbol{\Theta}) = Q_{\text{long}} + Q_{\text{surv}} + Q_{\text{RE}}$$

where:

- $Q_{\text{long}} = -\frac{1}{2\sigma_e^2}\sum_{i,j} [(V_{ij} - m_i(T_{ij}) - \hat{b}_i)^2 + \hat{v}_i] - \frac{N}{2}\log(2\pi\sigma_e^2)$
- $Q_{\text{surv}} = \sum_i [\delta_i(\log\lambda_i(T_i|0) + \hat{b}_i) - E[e^{b_i}|\mathcal{O}_i]\Lambda_i(T_i|0)]$
- $Q_{\text{RE}} = -\frac{1}{2\sigma_b^2}\sum_i (\hat{b}_i^2 + \hat{v}_i) - \frac{n}{2}\log(2\pi\sigma_b^2)$

**Optimization Strategy:**

1. **Survival parameters** $(\boldsymbol{\eta}, \boldsymbol{\alpha}, \boldsymbol{\phi})$:
   - Fix trajectory parameters
   - Optimize via L-BFGS with analytical gradients
2. **Trajectory parameters** $(\boldsymbol{\beta}, \boldsymbol{\theta})$:
   - Alternating optimization with constraint $\|\boldsymbol{\beta}\| = 1$
   - Iterate until convergence:
     - Fix $\boldsymbol{\theta}$, optimize $\boldsymbol{\beta}$
     - Fix $\boldsymbol{\beta}$, optimize $\boldsymbol{\theta}$
3. **Variance components** (closed-form):
   - $\sigma_e^2 = \frac{1}{N}\sum_{i,j}[(V_{ij} - m_i(T_{ij}) - \hat{b}_i)^2 + \hat{v}_i]$
   - $\sigma_b^2 = \frac{1}{n}\sum_i(\hat{b}_i^2 + \hat{v}_i)$

## Computational Details

### Gradient Computation

The M-step maximizes $Q(\boldsymbol{\Theta})$ using gradient-based optimization. All gradients decompose additively:
$$\nabla Q = \nabla Q_{\text{long}} + \nabla Q_{\text{surv}}$$

**Hazard parameters** ($\boldsymbol{\eta}$, $\boldsymbol{\alpha}$, $\boldsymbol{\phi}$) admit closed-form gradient expressions:

- $\nabla_{\boldsymbol{\eta}} Q = \sum_i [\delta_i \mathbf{B}^{(\lambda)}(T_i) - E[e^{b_i}|\mathcal{O}_i] \frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\eta}}]$
- $\nabla_{\boldsymbol{\alpha}} Q = \sum_i [\delta_i \mathbf{m}_i(T_i) - E[e^{b_i}|\mathcal{O}_i] \frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\alpha}}]$  
- $\nabla_{\boldsymbol{\phi}} Q = \sum_i [\delta_i - E[e^{b_i}|\mathcal{O}_i]\Lambda_i(T_i|0)] \mathbf{W}_i$

The computation of these gradients requires solving an augmented ODE system:

$$\frac{d}{dt}\begin{bmatrix}
\Lambda_i \\ m_i \\ \dot{m}_i \\ \partial\Lambda_{\eta,i} \\ \partial\Lambda_{\alpha,i}
\end{bmatrix} = \begin{bmatrix}
\lambda_i(t|0) \\ \dot{m}_i(t) \\ g(\boldsymbol{\beta}^{\top}\mathbf{Z}(t)) \\ \mathbf{B}^{(\lambda)}(t) \lambda_i(t|0) \\ \mathbf{m}(t) \lambda_i(t|0)
\end{bmatrix}$$

where $\partial\Lambda_{\eta,i}$ and $\partial\Lambda_{\alpha,i}$ are sensitivities with respect to $\boldsymbol{\eta}$ and $\boldsymbol{\alpha}$, respectively.

**Trajectory parameters** ($\boldsymbol{\beta}$, $\boldsymbol{\theta}$) have gradient expressions involving sensitivities:

- $\nabla_{\boldsymbol{\beta}} Q = \sum_{i,j} \frac{r_{ij}}{\sigma_e^2} \frac{\partial m_i(T_{ij})}{\partial \boldsymbol{\beta}} + \sum_i \left[\delta_i \boldsymbol{\alpha}^{\top} \frac{\partial \mathbf{m}_i(T_i)}{\partial \boldsymbol{\beta}} - E[e^{b_i}|\mathcal{O}_i] \frac{\partial \Lambda_i(T_i|0)}{\partial \boldsymbol{\beta}}\right]$

- $\nabla_{\boldsymbol{\theta}} Q = \sum_{i,j} \frac{r_{ij}}{\sigma_e^2} \frac{\partial m_i(T_{ij})}{\partial \boldsymbol{\theta}} + \sum_i \left[\delta_i \boldsymbol{\alpha}^{\top} \frac{\partial \mathbf{m}_i(T_i)}{\partial \boldsymbol{\theta}} - E[e^{b_i}|\mathcal{O}_i] \frac{\partial \Lambda_i(T_i|0)}{\partial \boldsymbol{\theta}}\right]$

where $r_{ij} = V_{ij} - m_i(T_{ij}) - \hat{b}_i$ denotes the residual.

The gradients with respect to $\boldsymbol{\beta}$ and $\boldsymbol{\theta}$ similarly require solving augmented ODE systems that track sensitivities.

For $\boldsymbol{\beta}$ sensitivities:
$$\frac{d}{dt}\begin{bmatrix}
m_i \\ \dot{m}_i \\ \partial m_{i,\beta} \\ \partial\dot{m}_{i,\beta} \\ \partial\Lambda_{\beta,i}
\end{bmatrix} = \begin{bmatrix}
\dot{m}_i(t) \\ g(\boldsymbol{\beta}^{\top}\mathbf{Z}(t)) \\ \partial \dot{m}_{i,\beta} \\ \boldsymbol{\theta}^{\top}\mathbf{B}'_g(u) \mathbf{Z}(t) \\ \boldsymbol{\alpha}^{\top}\frac{\partial\mathbf{m}_i(t)}{\partial\boldsymbol{\beta}} \lambda_i(t|0)
\end{bmatrix}$$

For $\boldsymbol{\theta}$ sensitivities:
$$\frac{d}{dt}\begin{bmatrix}
m_i \\ \dot{m}_i \\ \partial m_{i,\theta} \\ \partial\dot{m}_{i,\theta} \\ \partial\Lambda_{\theta,i}
\end{bmatrix} = \begin{bmatrix}
\dot{m}_i(t) \\ g(\boldsymbol{\beta}^{\top}\mathbf{Z}(t)) \\ \partial\dot{m}_{i,\theta} \\ \mathbf{B}_g(u) \\ \boldsymbol{\alpha}^{\top}\frac{\partial\mathbf{m}_i(t)}{\partial\boldsymbol{\beta}} \lambda_i(t|0)
\end{bmatrix}$$

where $\mathbf{B}'_g(u) = \frac{d\mathbf{B}_g(u)}{du}$ denotes the B-spline derivative basis.


### Convergence

The EM algorithm iterates until the relative change in log-likelihood falls below a specified threshold:

$$\frac{|\mathcal{L}^{(k+1)} - \mathcal{L}^{(k)}|}{|\mathcal{L}^{(k)}|} < \epsilon$$
